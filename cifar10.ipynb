{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYPq3cxCo9qYahSLNFAJ5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexbrandy/cifar10_classification/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaders"
      ],
      "metadata": {
        "id": "8ALFrTxrOuQv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1xgQ_dL7M9u9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def get_dataloaders(batch_size=5, show_images=True):\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    if show_images:\n",
        "        visualize_data(train_dataset)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_data(training_data):\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    cols, rows = 5, 2\n",
        "    for i in range(1, cols * rows + 1):\n",
        "\n",
        "        sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "\n",
        "        img, label = training_data[sample_idx]\n",
        "\n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.title(CLASSES[label])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        img = img / 2 + 0.5\n",
        "        np_img = np.transpose(img, (1, 2, 0))\n",
        "        plt.imshow(np_img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "52FTvWVmkQam"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n",
        "\n",
        "In this model we will implement a convolutional neural network that is used to process the images.\n",
        "\n",
        "In this network we feed the the input first through a convolution layer then a max pooling layer and then a second convolution layer, after this it is fed through 3 linear layers.\n",
        "\n",
        "## Convolution Layer\n",
        "\n",
        "Convolution layers apply filters to the image that help highlight specific details that may be important during the classification task. In the following gif you can see how a convolution layer is applied to a matrix.\n",
        "\n",
        "![Convolution](https://miro.medium.com/v2/resize:fit:400/format:webp/1*rRT3tkMOKX-8c7nqW_iHLQ.gif)\n",
        "\n",
        "## Max pooling\n",
        "\n",
        "Max pooling effects the image by taking groups of pixel and aggregating them together to get a reduced version of the image that retains the important features.\n",
        "\n",
        "![Max pooling](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*76nyDxRFl2ZUseO6ymEXAw.png)\n",
        "\n",
        "## Calculating convolution and max pooling\n",
        "\n",
        "To calculate the output of convolution and pooling layers we use this formula\n",
        "\n",
        "**[(Wâˆ’K+2P)/S]+1**\n",
        "\n",
        "W is the input volume\n",
        "\n",
        "K is the Kernel size\n",
        "\n",
        "P is the padding\n",
        "\n",
        "S is the stride\n",
        "\n"
      ],
      "metadata": {
        "id": "cFMv_YE0mpjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SY4JVUQihP7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as f\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pool(f.relu(self.conv1(x)))\n",
        "        output = self.pool(f.relu(self.conv2(output)))\n",
        "        output = torch.flatten(output, 1) # flatten all dimensions except batch size\n",
        "        output = f.relu(self.fc1(output))\n",
        "        output = f.relu(self.fc2(output))\n",
        "        output = self.fc3(output)\n",
        "        return output\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3kz35D47m9ti"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "yC3rQn9PmtbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    pass"
      ],
      "metadata": {
        "id": "lN1MuLfHnkxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "ekBLyy2PmwR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    pass"
      ],
      "metadata": {
        "id": "qb700-50nnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "37ppzk1tm0Pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Loop"
      ],
      "metadata": {
        "id": "Wi5AMhX8npZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    pass"
      ],
      "metadata": {
        "id": "t0ZWVGJnnrDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}